{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import plotly.figure_factory as ff\n",
    "from typing import List, Dict\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# -- Local imports\n",
    "from utils.elasticsearch_utils import get_all_hits, flatten_dict, flatten_dict_keys, \\\n",
    "    get_hits_dsl_query, \\\n",
    "    get_hits_dict_query, update_fields_select_df, get_server_reports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# -- Useful paths\n",
    "OUT_DIR = \"results/reports\"\n",
    "eDATA_FILTER_FILE = \"configs/edata_fields.csv\"\n",
    "rDATA_FILTER_FILE = \"configs/reporting_fields.csv\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# -- Example of elasticsearch data fetch\n",
    "\n",
    "# -- Simple Gather all data from elasticsearch\n",
    "full_edata: List[Dict] = get_all_hits()\n",
    "\n",
    "edata: List[Dict] = get_hits_dsl_query({\n",
    "    \"match\": {\n",
    "        \"args.title\": {\n",
    "            \"query\": \"andrei\",\n",
    "            \"type\": \"phrase\"\n",
    "        }\n",
    "    }\n",
    "})\n",
    "\n",
    "edata: List[Dict] = get_hits_dict_query({\n",
    "    \"args.title\": [\"andrei\"], \n",
    "    \"args.tasks.datasets\": [\"mnist\", \"cifar10\"]\n",
    "})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# -- Simple fetch of report from server \n",
    "rdata: List[Dict] = get_server_reports(e_ids=[\"E1sZ62MBm5wd3rDHL-EF\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# -- Key filters for reports or eData\n",
    "rdata_keys = [] # Empty if you do not want to update keys\n",
    "edata_keys = []\n",
    "\n",
    "# eDATA columns read \n",
    "edata_keys = sorted(list(flatten_dict_keys(edata[0])))  # Use tu update / initialize\n",
    "\n",
    "# Reporting columns read \n",
    "rdata_keys = sorted(list(flatten_dict_keys(rdata[0])))  # Use tu update / initialize\n",
    "\n",
    "# -- Read /update them to file\n",
    "# Read key filters and smarg_grop prop for eData \n",
    "e_select_df, e_select_k, e_select_sg = update_fields_select_df(None, edata_keys, \n",
    "                                                               update_file=eDATA_FILTER_FILE)\n",
    "\n",
    "# Read key filters and smarg_grop prop for raw reporting data \n",
    "r_select_df, r_select_k, r_select_sg = update_fields_select_df(None, rdata_keys, \n",
    "                                                               update_file=rDATA_FILTER_FILE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\n",
    "edata: List[Dict] = get_hits_dict_query({\n",
    "    \"args.title\": [\"andrei\"]}, include_keys=e_select_k)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example of Gathering raw data from server\n",
    "\n",
    "import seaborn as sns; sns.set(color_codes=True)\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "full_report, df_return = get_server_reports(experiments=[\"3d_datasets_ewc_256_mlp\"],\n",
    "                                            include_keys=r_select_k, smart_group=r_select_sg,\n",
    "                                            df_format=True)\n",
    "df, report_info = df_return\n",
    "\n",
    "optim_name = \"_args.train._optimizer.__name.\"\n",
    "optimizers = df[optim_name].unique()\n",
    "seen_idxs = df[\"seen\"].unique()\n",
    "\n",
    "for task_idx in df[\"task_idx\"].unique():\n",
    "    df_task = df[df[\"task_idx\"] == task_idx]\n",
    "\n",
    "cnt = df_task.groupby([\"seen\", optim_name]).count()[\"task_idx\"].describe()\n",
    "select = int(cnt[\"75%\"])\n",
    "\n",
    "df_task[\"c_reporting_idx\"] = df_task.groupby([\"seen\", optim_name]).cumcount()\n",
    "\n",
    "ax = sns.tsplot(data=df_task, time=\"seen\", value=\"_eval_trace.0.acc.2\", \n",
    "                condition=\"_args.train._optimizer.__name.\")\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df.to_csv(\"test2.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
